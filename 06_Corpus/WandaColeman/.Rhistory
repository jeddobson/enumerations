group2<-c("PoetryAuthors_German_Hypernyms")
dir1<-paste("~/Sites/Topologies - Data/Topologies - Data (Poetry)/PoetryCorpusesAuthor/", group1, sep="")
dir2<-paste("~/Sites/Topologies - Data/Topologies - Data (Poetry)/PoetryCorpusesAuthor/", group2, sep="")
filenames1<-list.files(group1, full.names = FALSE)
filenames2<-list.files(group2, full.names=FALSE)
language1<-c("German")
library("tm")
library("SnowballC")
library("RWeka")
root<-c("~/Sites/Topologies - Data/Topologies - Data (Poetry)/PoetryCorpusesAuthor/")
setwd(root)
group1<-c("PoetryAuthors_German")
group2<-c("PoetryAuthors_German_Hypernyms")
dir1<-paste("~/Sites/Topologies - Data/Topologies - Data (Poetry)/PoetryCorpusesAuthor/", group1, sep="")
dir2<-paste("~/Sites/Topologies - Data/Topologies - Data (Poetry)/PoetryCorpusesAuthor/", group2, sep="")
filenames1<-list.files(group1, full.names = FALSE)
filenames2<-list.files(group2, full.names=FALSE)
language1<-c("German")
final.df<-NULL
i=1
setwd(dir1)
corpus1 <- VCorpus(DirSource(filenames1[i]), readerControl=list(language=language1))
corpus1 <- tm_map(corpus1, content_transformer(stripWhitespace))
corpus1 <- tm_map(corpus1, content_transformer(tolower))
corpus1 <- tm_map(corpus1, content_transformer(removePunctuation))
corpus1 <- tm_map(corpus1, content_transformer(removeNumbers))
corpus1.dtm<-DocumentTermMatrix(corpus1, control=list(wordLengths=c(1,Inf)))
corpus1.matrix<-as.matrix(corpus1.dtm, stringsAsFactors=F)
#load hypernyms
setwd(dir2)
corpus2 <- VCorpus(DirSource(filenames2[i]), readerControl=list(language=language1))
corpus2 <- tm_map(corpus2, content_transformer(stripWhitespace))
corpus2 <- tm_map(corpus2, content_transformer(tolower))
corpus2 <- tm_map(corpus2, content_transformer(function(x) gsub("_", " ", x)))
corpus2.dtm<-DocumentTermMatrix(corpus2, control=list(wordLengths=c(1,Inf)))
corpus2.matrix<-as.matrix(corpus2.dtm, stringsAsFactors=F)
#divide into early and late
final.quart<-round(nrow(corpus2.matrix)/4) #this is the definition of the late period
late.hyp<-corpus2.matrix[(nrow(corpus2.matrix)-(final.quart-1)):nrow(corpus2.matrix),]
late.hyp<-late.hyp[,colSums(late.hyp) != 0]
early.reg<-corpus1.matrix[1:(nrow(corpus1.matrix)-final.quart),]
early.reg<-early.reg[,colSums(early.reg) != 0]
late.reg<-corpus1.matrix[(nrow(corpus1.matrix)-(final.quart-1)):nrow(corpus1.matrix),]
late.reg<-late.reg[,colSums(late.reg) != 0]
early.hyp<-corpus2.matrix[1:(nrow(corpus2.matrix)-final.quart),]
early.hyp<-early.hyp[,colSums(early.hyp) != 0]
result.df<-late.reg[,which(colnames(late.reg) %in% colnames(early.hyp))]
result.df
View(result.df)
late.actual<-sum(late.reg[,which(colnames(late.reg) %in% colnames(early.hyp))])/sum(late.reg)
late.actual
early.actual<-sum(early.reg[,which(colnames(early.reg) %in% colnames(late.hyp))])/sum(early.reg)
early.actual
hyp.perm<-corpus2.matrix[sample(nrow(corpus2.matrix), nrow(corpus2.matrix)),]
View(hyp.perm)
reg.perm<-corpus1.matrix[sample(nrow(corpus1.matrix), nrow(corpus1.matrix)),]
test<-late.actual-early.actual
test
hyp.perm<-corpus2.matrix[sample(nrow(corpus2.matrix), nrow(corpus2.matrix)),]
reg.perm<-corpus1.matrix[sample(nrow(corpus1.matrix), nrow(corpus1.matrix)),]
#early hypernyms (no this is not mislabeled)
late.hyp<-hyp.perm[(nrow(hyp.perm)-(final.quart-1)):nrow(hyp.perm),]
late.hyp<-late.hyp[,colSums(late.hyp) != 0]
early.reg<-reg.perm[1:(nrow(reg.perm)-final.quart),]
early.reg<-early.reg[,colSums(early.reg) != 0]
#late hypernyms (ditto)
late.reg<-reg.perm[(nrow(reg.perm)-(final.quart-1)):nrow(reg.perm),]
late.reg<-late.reg[,colSums(late.reg) != 0]
early.hyp<-hyp.perm[1:(nrow(hyp.perm)-final.quart),]
early.hyp<-early.hyp[,colSums(early.hyp) != 0]
#calculate test statistic = late hypernymy minus early hypernymy
#hypernymy = % reg words of corpus A in hypernyms of corpus B
late.p<-sum(late.reg[,which(colnames(late.reg) %in% colnames(early.hyp))])/sum(late.reg)
early.p<-sum(early.reg[,which(colnames(early.reg) %in% colnames(late.hyp))])/sum(early.reg)
test.p<-late.p-early.p
test.p
pred.v<-vector()
for (j in 1:1000){
#permute both samples
hyp.perm<-corpus2.matrix[sample(nrow(corpus2.matrix), nrow(corpus2.matrix)),]
reg.perm<-corpus1.matrix[sample(nrow(corpus1.matrix), nrow(corpus1.matrix)),]
#early hypernyms (no this is not mislabeled)
late.hyp<-hyp.perm[(nrow(hyp.perm)-(final.quart-1)):nrow(hyp.perm),]
late.hyp<-late.hyp[,colSums(late.hyp) != 0]
early.reg<-reg.perm[1:(nrow(reg.perm)-final.quart),]
early.reg<-early.reg[,colSums(early.reg) != 0]
#late hypernyms (ditto)
late.reg<-reg.perm[(nrow(reg.perm)-(final.quart-1)):nrow(reg.perm),]
late.reg<-late.reg[,colSums(late.reg) != 0]
early.hyp<-hyp.perm[1:(nrow(hyp.perm)-final.quart),]
early.hyp<-early.hyp[,colSums(early.hyp) != 0]
#calculate test statistic = late hypernymy minus early hypernymy
#hypernymy = % reg words of corpus A in hypernyms of corpus B
late.p<-sum(late.reg[,which(colnames(late.reg) %in% colnames(early.hyp))])/sum(late.reg)
early.p<-sum(early.reg[,which(colnames(early.reg) %in% colnames(late.hyp))])/sum(early.reg)
test.p<-late.p-early.p
pred.v<-append(pred.v,test.p)
}
j
late.generality.diff<-test
late.generality.diff
author<-filenames1[i]
author
language<-language1
language
quantile(pred.v, c(.975))
test
quantile(pred.v, c(.025))
test
a<-read.csv("Difficulty_Results_All.csv")
setwd("~/Documents/2. Books/Enumerations/Enumerations - Chap 6 (Corpus)/Corpus - Graphs and Tables")
a<-read.csv("Difficulty_Results_All.csv")
gc()
b<-read.csv("Syntactic_Irregularity_All.csv")
c<-read.csv("TTR_All_Late.csv")
d<-read.csv("Concreteness_All.csv")
a<-read.csv("Difficulty_Results_All.csv")
b<-read.csv("Syntactic_Irregularity_All.csv")
c<-read.csv("TTR_All_Late.csv")
d<-read.csv("Concreteness_All.csv")
View(a)
which(a$author != b$author)
View(a)
View(b)
a<-a[order(a$author),]
b<-b[order(b$author),]
c<-c[order(c$author),]
d<-d[order(d$author),]
d<-d[order(d$author),]
which(a$author != c$author)
View(c)
all<-data.frame(a$author, a$late.tuldava.difference, b$late.irregularity.difference, c$late.richness.difference, d$late.concreteness.diff)
View(all)
pca<-princomp(all)
View(a)
View(all)
row.names(all)<-all$a.author
all<-all[,-1]
pca<-princomp(all)
biplot(pca)
View(all)
plot(pca)
biplot(pca)
library("tm")
library("SnowballC")
library("RWeka")
root<-c("~/Sites/Topologies - Data/Topologies - Data (Poetry)/PoetryCorpusesAuthor/")
setwd(root)
group1<-c("PoetryAuthors_German")
group2<-c("PoetryAuthors_German_Hypernyms")
dir1<-paste("~/Sites/Topologies - Data/Topologies - Data (Poetry)/PoetryCorpusesAuthor/", group1, sep="")
dir2<-paste("~/Sites/Topologies - Data/Topologies - Data (Poetry)/PoetryCorpusesAuthor/", group2, sep="")
filenames1<-list.files(group1, full.names = FALSE)
filenames2<-list.files(group2, full.names=FALSE)
language1<-c("German")
final.df<-NULL
for (i in 1:length(filenames1)){
#load regular words
setwd(dir1)
corpus1 <- VCorpus(DirSource(filenames1[i]), readerControl=list(language=language1))
corpus1 <- tm_map(corpus1, content_transformer(stripWhitespace))
corpus1 <- tm_map(corpus1, content_transformer(tolower))
corpus1 <- tm_map(corpus1, content_transformer(removePunctuation))
corpus1 <- tm_map(corpus1, content_transformer(removeNumbers))
corpus1.dtm<-DocumentTermMatrix(corpus1, control=list(wordLengths=c(1,Inf)))
corpus1.matrix<-as.matrix(corpus1.dtm, stringsAsFactors=F)
#load hypernyms
setwd(dir2)
corpus2 <- VCorpus(DirSource(filenames2[i]), readerControl=list(language=language1))
corpus2 <- tm_map(corpus2, content_transformer(stripWhitespace))
corpus2 <- tm_map(corpus2, content_transformer(tolower))
corpus2 <- tm_map(corpus2, content_transformer(function(x) gsub("_", " ", x)))
corpus2.dtm<-DocumentTermMatrix(corpus2, control=list(wordLengths=c(1,Inf)))
corpus2.matrix<-as.matrix(corpus2.dtm, stringsAsFactors=F)
#divide into early and late
final.quart<-round(nrow(corpus2.matrix)/4) #this is the definition of the late period
#early hypernyms (no this is not mislabeled)
late.hyp<-corpus2.matrix[(nrow(corpus2.matrix)-(final.quart-1)):nrow(corpus2.matrix),]
late.hyp<-late.hyp[,colSums(late.hyp) != 0]
early.reg<-corpus1.matrix[1:(nrow(corpus1.matrix)-final.quart),]
early.reg<-early.reg[,colSums(early.reg) != 0]
#late hypernyms (ditto)
late.reg<-corpus1.matrix[(nrow(corpus1.matrix)-(final.quart-1)):nrow(corpus1.matrix),]
late.reg<-late.reg[,colSums(late.reg) != 0]
early.hyp<-corpus2.matrix[1:(nrow(corpus2.matrix)-final.quart),]
early.hyp<-early.hyp[,colSums(early.hyp) != 0]
#calculate test statistic = late hypernymy minus early hypernymy
#hypernymy = % reg words of corpus A in hypernyms of corpus B
late.actual<-sum(late.reg[,which(colnames(late.reg) %in% colnames(early.hyp))])/sum(late.reg)
early.actual<-sum(early.reg[,which(colnames(early.reg) %in% colnames(late.hyp))])/sum(early.reg)
test<-late.actual-early.actual
#run randomization test
pred.v<-vector()
for (j in 1:1000){
#permute both samples
hyp.perm<-corpus2.matrix[sample(nrow(corpus2.matrix), nrow(corpus2.matrix)),]
reg.perm<-corpus1.matrix[sample(nrow(corpus1.matrix), nrow(corpus1.matrix)),]
#early hypernyms (no this is not mislabeled)
late.hyp<-hyp.perm[(nrow(hyp.perm)-(final.quart-1)):nrow(hyp.perm),]
late.hyp<-late.hyp[,colSums(late.hyp) != 0]
early.reg<-reg.perm[1:(nrow(reg.perm)-final.quart),]
early.reg<-early.reg[,colSums(early.reg) != 0]
#late hypernyms (ditto)
late.reg<-reg.perm[(nrow(reg.perm)-(final.quart-1)):nrow(reg.perm),]
late.reg<-late.reg[,colSums(late.reg) != 0]
early.hyp<-hyp.perm[1:(nrow(hyp.perm)-final.quart),]
early.hyp<-early.hyp[,colSums(early.hyp) != 0]
#calculate test statistic = late hypernymy minus early hypernymy
#hypernymy = % reg words of corpus A in hypernyms of corpus B
late.p<-sum(late.reg[,which(colnames(late.reg) %in% colnames(early.hyp))])/sum(late.reg)
early.p<-sum(early.reg[,which(colnames(early.reg) %in% colnames(late.hyp))])/sum(early.reg)
test.p<-late.p-early.p
pred.v<-append(pred.v,test.p)
}
if (test > quantile(pred.v, c(.975))[[1]]){
generality<-c("late")
#question 2: does the late period have a significantly lower ratio of things to abstractions than by chance?
} else if (test < quantile(pred.v, c(.025))[[1]]){
generality<-c("early")
#or is there no difference between late and early period in terms of the thing/abstraction ratio
} else {
generality<-c("neither")
}
late.generality.diff<-test
author<-filenames1[i]
language<-language1
temp.df<-data.frame(author, language, generality, late.generality.diff)
final.df<-rbind(final.df, temp.df)
}
final.df<-NULL
for (i in 1:length(filenames1)){
print(i)
#load regular words
setwd(dir1)
corpus1 <- VCorpus(DirSource(filenames1[i]), readerControl=list(language=language1))
corpus1 <- tm_map(corpus1, content_transformer(stripWhitespace))
corpus1 <- tm_map(corpus1, content_transformer(tolower))
corpus1 <- tm_map(corpus1, content_transformer(removePunctuation))
corpus1 <- tm_map(corpus1, content_transformer(removeNumbers))
corpus1.dtm<-DocumentTermMatrix(corpus1, control=list(wordLengths=c(1,Inf)))
corpus1.matrix<-as.matrix(corpus1.dtm, stringsAsFactors=F)
#load hypernyms
setwd(dir2)
corpus2 <- VCorpus(DirSource(filenames2[i]), readerControl=list(language=language1))
corpus2 <- tm_map(corpus2, content_transformer(stripWhitespace))
corpus2 <- tm_map(corpus2, content_transformer(tolower))
corpus2 <- tm_map(corpus2, content_transformer(function(x) gsub("_", " ", x)))
corpus2.dtm<-DocumentTermMatrix(corpus2, control=list(wordLengths=c(1,Inf)))
corpus2.matrix<-as.matrix(corpus2.dtm, stringsAsFactors=F)
#divide into early and late
final.quart<-round(nrow(corpus2.matrix)/4) #this is the definition of the late period
#early hypernyms (no this is not mislabeled)
late.hyp<-corpus2.matrix[(nrow(corpus2.matrix)-(final.quart-1)):nrow(corpus2.matrix),]
late.hyp<-late.hyp[,colSums(late.hyp) != 0]
early.reg<-corpus1.matrix[1:(nrow(corpus1.matrix)-final.quart),]
early.reg<-early.reg[,colSums(early.reg) != 0]
#late hypernyms (ditto)
late.reg<-corpus1.matrix[(nrow(corpus1.matrix)-(final.quart-1)):nrow(corpus1.matrix),]
late.reg<-late.reg[,colSums(late.reg) != 0]
early.hyp<-corpus2.matrix[1:(nrow(corpus2.matrix)-final.quart),]
early.hyp<-early.hyp[,colSums(early.hyp) != 0]
#calculate test statistic = late hypernymy minus early hypernymy
#hypernymy = % reg words of corpus A in hypernyms of corpus B
late.actual<-sum(late.reg[,which(colnames(late.reg) %in% colnames(early.hyp))])/sum(late.reg)
early.actual<-sum(early.reg[,which(colnames(early.reg) %in% colnames(late.hyp))])/sum(early.reg)
test<-late.actual-early.actual
#run randomization test
pred.v<-vector()
for (j in 1:1000){
#permute both samples
hyp.perm<-corpus2.matrix[sample(nrow(corpus2.matrix), nrow(corpus2.matrix)),]
reg.perm<-corpus1.matrix[sample(nrow(corpus1.matrix), nrow(corpus1.matrix)),]
#early hypernyms (no this is not mislabeled)
late.hyp<-hyp.perm[(nrow(hyp.perm)-(final.quart-1)):nrow(hyp.perm),]
late.hyp<-late.hyp[,colSums(late.hyp) != 0]
early.reg<-reg.perm[1:(nrow(reg.perm)-final.quart),]
early.reg<-early.reg[,colSums(early.reg) != 0]
#late hypernyms (ditto)
late.reg<-reg.perm[(nrow(reg.perm)-(final.quart-1)):nrow(reg.perm),]
late.reg<-late.reg[,colSums(late.reg) != 0]
early.hyp<-hyp.perm[1:(nrow(hyp.perm)-final.quart),]
early.hyp<-early.hyp[,colSums(early.hyp) != 0]
#calculate test statistic = late hypernymy minus early hypernymy
#hypernymy = % reg words of corpus A in hypernyms of corpus B
late.p<-sum(late.reg[,which(colnames(late.reg) %in% colnames(early.hyp))])/sum(late.reg)
early.p<-sum(early.reg[,which(colnames(early.reg) %in% colnames(late.hyp))])/sum(early.reg)
test.p<-late.p-early.p
pred.v<-append(pred.v,test.p)
}
if (test > quantile(pred.v, c(.975))[[1]]){
generality<-c("late")
#question 2: does the late period have a significantly lower ratio of things to abstractions than by chance?
} else if (test < quantile(pred.v, c(.025))[[1]]){
generality<-c("early")
#or is there no difference between late and early period in terms of the thing/abstraction ratio
} else {
generality<-c("neither")
}
late.generality.diff<-test
author<-filenames1[i]
language<-language1
temp.df<-data.frame(author, language, generality, late.generality.diff)
final.df<-rbind(final.df, temp.df)
}
setwd("~/Documents/2. Books/Enumerations/Enumerations - Chap 6 (Corpus)/Corpus - Graphs and Tables")
a<-read.csv("Difficulty_Results_All.csv")
b<-read.csv("Syntactic_Irregularity_All.csv")
c<-read.csv("TTR_All_Late.csv")
d<-read.csv("Concreteness_All.csv")
#e<-read.csv("Generality_All.csv")
a<-a[order(a$author),]
b<-b[order(b$author),]
c<-c[order(c$author),]
d<-d[order(d$author),]
which(a$author != c$author)
all<-data.frame(a$author, a$late.tuldava.difference, b$late.irregularity.difference, c$late.richness.difference, d$late.concreteness.diff)
row.names(all)<-all$a.author
all<-all[,-1]
View(all)
View(all)
View(all)
View(all)
View(a)
all.late<-data.frame(a$author, a$difficulty, b$irregularity, c$richness, d$concreteness)
View(all.late)
i=1
sub<-all.late[i,]
View(sub)
which(sub[1,] == "late")
View(sub)
late.s<-length(which(sub[1,] == "late"))
late.s
late.score<-vector()
for (i in 1:nrow(all.late)){
sub<-all.late[i,]
late.s<-length(which(sub[1,] == "late"))
late.score<-append(late.score, late.s)
}
late.score
all.late$late.score<-late.score
View(all.late)
View(all.late)
late.s<-length(which(sub[1,2:4] == "late"))
late.s
which(sub[1,2:4] == "late")
View(sub)
all.late<-data.frame(a$author, a$difficulty, b$irregularity, c$richness, d$concreteness)
late.score<-vector()
for (i in 1:nrow(all.late)){
sub<-all.late[i,]
late.s1<-length(which(sub[1,2:4] == "late"))
late.s2<-length(which(sub[1,5] == "early"))
late.s<-late.s1+late.s2
late.score<-append(late.score, late.s)
}
all.late$late.score<-late.score
View(all.late)
length(which(all.late$late.score > 0))
length(which(all.late$late.score > 0))/nrow(all.late)
length(which(all.late$late.score > 1))/nrow(all.late)
View(all.late)
setwd("~/Sites/Topologies - Data/Topologies - Data (Poetry)/PoetryCorpusesAuthor/PoetryAuthors_English_Vulnerability")
a<-read.csv("WandaColeman_Vulnerability_Table.csv")
View(all.late)
View(a)
ggplot(a, aes(x=X, y=obs.roll/100)) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5, size=tit.size), plot.caption = element_text(hjust = 0.5, size=10), panel.grid.minor = element_blank(), panel.grid.major = element_blank()) +
geom_line() +
geom_line(aes(x=X, y=a$high.roll/100), linetype="dotted") +
geom_line(aes(x=X, y=a$low.roll/100), linetype="dotted") +
labs(x="Poems", y="Similarity")
ggplot(a, aes(x=X, y=obs.roll/100)) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5), plot.caption = element_text(hjust = 0.5, size=10), panel.grid.minor = element_blank(), panel.grid.major = element_blank()) +
geom_line() +
geom_line(aes(x=X, y=a$high.roll/100), linetype="dotted") +
geom_line(aes(x=X, y=a$low.roll/100), linetype="dotted") +
labs(x="Poems", y="Similarity")
ggplot(a, aes(x=X, y=obs.roll/100)) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5), plot.caption = element_text(hjust = 0.5, size=10), panel.grid.minor = element_blank(), panel.grid.major = element_blank()) +
geom_line() +
geom_line(aes(x=X, y=a$high.roll/100), linetype="dotted") +
geom_line(aes(x=X, y=a$low.roll/100), linetype="dotted") +
ylim(0.025, 0.08) +
labs(x="Poems", y="Similarity")
ggplot(a, aes(x=X, y=obs.roll/100)) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5), plot.caption = element_text(hjust = 0.5, size=10), panel.grid.minor = element_blank(), panel.grid.major = element_blank()) +
geom_line() +
geom_line(aes(x=X, y=a$high.roll/100), linetype="dotted") +
geom_line(aes(x=X, y=a$low.roll/100), linetype="dotted") +
ylim(0.025, 0.08) +
labs(x="Poems over time", y="Similarity")
ggplot(a, aes(x=X, y=obs.roll/100)) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5), plot.caption = element_text(hjust = 0.5, size=10), panel.grid.minor = element_blank(), panel.grid.major = element_blank()) +
geom_line() +
geom_line(aes(x=X, y=a$high.roll/100), linetype="dashed") +
geom_line(aes(x=X, y=a$low.roll/100), linetype="dashed") +
ylim(0.025, 0.08) +
labs(x="Poems over time", y="Similarity")
ggplot(a, aes(x=X, y=obs.roll/100)) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5), plot.caption = element_text(hjust = 0.5, size=10), panel.grid.minor = element_blank(), panel.grid.major = element_blank()) +
geom_line() +
geom_line(aes(x=X, y=a$high.roll/100), linetype="dotted") +
geom_line(aes(x=X, y=a$low.roll/100), linetype="dotted") +
ylim(0.025, 0.08) +
labs(x="Poems over time", y="Similarity")
ggplot(a, aes(x=X, y=obs.roll/100)) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5), plot.caption = element_text(hjust = 0.5, size=10), panel.grid.minor = element_blank(), panel.grid.major = element_blank()) +
geom_line() +
geom_line(aes(x=X, y=a$high.roll/100), linetype="dotted") +
geom_line(aes(x=X, y=a$low.roll/100), linetype="dotted") +
geom_vline(xintercept = 596, linetype = "dashed") +
geom_vline(xintercept = 766, linetype = "dashed") +
ylim(0.025, 0.08) +
labs(x="Poems over time", y="Similarity")
ggplot(a, aes(x=X, y=obs.roll/100)) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5), plot.caption = element_text(hjust = 0.5, size=10), panel.grid.minor = element_blank(), panel.grid.major = element_blank()) +
geom_line() +
geom_line(aes(x=X, y=a$high.roll/100), linetype="dotted") +
geom_line(aes(x=X, y=a$low.roll/100), linetype="dotted") +
geom_vline(xintercept = 596) +
geom_vline(xintercept = 766) +
ylim(0.025, 0.08) +
labs(x="Poems over time", y="Similarity")
ggplot(a, aes(x=X, y=obs.roll/100)) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5), plot.caption = element_text(hjust = 0.5, size=10), panel.grid.minor = element_blank(), panel.grid.major = element_blank()) +
geom_line() +
geom_line(aes(x=X, y=a$high.roll/100), linetype="dotted") +
geom_line(aes(x=X, y=a$low.roll/100), linetype="dotted") +
geom_vline(xintercept = 596) +
geom_vline(xintercept = 766) +
ylim(0.025, 0.08) +
#labs(x="Poems over time", y="Similarity")
labs(x="Poems over time", y="Similarity", caption="\nFig. 6.7 Local vulnerability in the poetry of Wanda Coleman.\n\nSource: Andrew Piper, Enumerations: The Quantities of Literature (2018)")
ggplot(a, aes(x=X, y=obs.roll/100)) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5), plot.caption = element_text(hjust = 0.5, size=10), panel.grid.minor = element_blank(), panel.grid.major = element_blank()) +
geom_line() +
geom_line(aes(x=X, y=a$high.roll/100), linetype="dotted") +
geom_line(aes(x=X, y=a$low.roll/100), linetype="dotted") +
geom_vline(xintercept = 596) +
geom_vline(xintercept = 766) +
ylim(0.025, 0.08) +
#labs(x="Poems over time", y="Similarity")
labs(x="Poems over time", y="Similarity", caption="\nFig. 6.7 Local vulnerability in the poetry of Wanda Coleman.\nVertical bars represent the collection Bathwater Wine (1998)\n\nSource: Andrew Piper, Enumerations: The Quantities of Literature (2018)")
require("NLP")
library("openNLP")
library("openNLPdata")
#Step 1: Run measure
sent_token_annotator <- Maxent_Sent_Token_Annotator(language = "en")
#word_token_annotator <- Maxent_Word_Token_Annotator(language = "en")
#pos_tag_annotator <- Maxent_POS_Tag_Annotator(language = "en")
setwd("~/Documents/2. Books/Enumerations/Enumerations - Chap 6 (Corpus)/Corpus - Graphs and Tables")
filenames<-list.files("WandaColeman", pattern="*.txt", full.names=FALSE)
setwd("~/Documents/2. Books/Enumerations/Enumerations - Chap 6 (Corpus)/Corpus - Graphs and Tables/WandaColeman")
#establish function to split sentences into words to assess sentence length
splitSentence<-function(x){
x<-unlist(strsplit(x, " "))
x<-x[x != ""]
x<-length(x)
}
length.df<-NULL
for (i in 1:length(filenames)) {
work<-scan(filenames[i], what="character", quote="")
work.clean<- gsub("\\d", "", work)
text.whole<-paste(work.clean, collapse=" ") # collapse into single chunk
text.char<-as.String(text.whole)
a1 <- annotate(text.char, sent_token_annotator)
sentences<-text.char[a1]
length.v<-unlist(lapply(sentences, splitSentence))
mean.len<-mean(length.v)
poem<-filenames[i]
temp.df<-data.frame(poem, mean.len)
length.df<-rbind(length.df, temp.df)
}
require("NLP")
library("openNLP")
library("openNLPdata")
sent_token_annotator <- Maxent_Sent_Token_Annotator(language = "en")
#word_token_annotator <- Maxent_Word_Token_Annotator(language = "en")
#pos_tag_annotator <- Maxent_POS_Tag_Annotator(language = "en")
setwd("~/Documents/2. Books/Enumerations/Enumerations - Chap 6 (Corpus)/Corpus - Graphs and Tables")
filenames<-list.files("WandaColeman", pattern="*.txt", full.names=FALSE)
setwd("~/Documents/2. Books/Enumerations/Enumerations - Chap 6 (Corpus)/Corpus - Graphs and Tables/WandaColeman")
#establish function to split sentences into words to assess sentence length
splitSentence<-function(x){
x<-unlist(strsplit(x, " "))
x<-x[x != ""]
x<-length(x)
}
length.df<-NULL
for (i in 1:length(filenames)) {
work<-scan(filenames[i], what="character", quote="")
work.clean<- gsub("\\d", "", work)
text.whole<-paste(work.clean, collapse=" ") # collapse into single chunk
text.char<-as.String(text.whole)
a1 <- annotate(text.char, sent_token_annotator)
sentences<-text.char[a1]
length.v<-unlist(lapply(sentences, splitSentence))
mean.len<-mean(length.v)
poem<-filenames[i]
temp.df<-data.frame(poem, mean.len)
length.df<-rbind(length.df, temp.df)
}
