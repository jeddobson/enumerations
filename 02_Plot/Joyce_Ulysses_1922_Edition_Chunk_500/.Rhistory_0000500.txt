(k in 3:152) { dir <- paste("/Users/andrewpiper/Sites/Topologies - Tests/Semantics of 
Life/Conversionality Test/Conversionality Test - Binary/Binary Test 1/binarytest1_new/DataNovelGerman20/", as.character(k), sep="") #load 
corpus conversion <- Corpus(DirSource(dir), readerControl=list(language="German")) conversion <- tm_map(conversion, function(x) iconv(enc2utf8(x), 
sub = "byte")) conversion <- tm_map(conversion, stripWhitespace) conversion <- tm_map(conversion, 
tolower) conversion <- tm_map(conversion, removePunctuation) conversion <- tm_map(conversion, removeNumbers) #remove 
problem words problems<-c("apparat","datumsangaben","seite","page","erlÃ¤uterungen", "kommentar") conversion <- tm_map(conversion, removeWords, problems) #dtm 
conversion.dtm<-DocumentTermMatrix(conversion, control=list(wordLengths=c(1,Inf))) #get scaling value conversion.matrix<-as.matrix(conversion.dtm, stringsAsFactors=F) scaling<-rowSums(conversion.matrix) #remove stopwords 
conversion <- tm_map(conversion, removeWords, stopwords("German")) #words<-c("ab", "ac", "ad ", "adhic 
", "aliqui ", "aliquis ", "an", "ante", "apud", "at", "atque", 
"aut", "autem", "cum", "cur", "de", "deinde", "dum", "ego", "enim", "ergo", 
"es", "est", "et", "etiam", "etsi", "ex", "fio", "haud", "hic", "iam", 
"idem", "igitur", "ille", "in", "infra", "inter", "interim", "ipse", "is", "ita", 
"magis", "modo", "mox", "nam", "ne", "nec", "necque", "neque", "nisi", "non", 
"nos", "o", "ob", "per", "possum", "post", "pro", "quae", "quam", "quare", 
"qui", "quia", "quicumque", "quidem", "quilibet", "quis", "quisnam", "quisquam", "quisque", "quisquis", 
"quo", "quoniam", "sed", "si", "sic", "sive", "sub", "sui", "sum", "super", 
"suus", "tam", "tamen", "trans", "tu", "tum", "ubi", "uel", "uero") #remove 
Latin stop words #conversion <- tm_map(conversion, removeWords, words) #remake dtm 
conversion.dtm<-DocumentTermMatrix(conversion, control=list(wordLengths=c(1,Inf))) #remove sparse words conversion.sparse.dtm<- removeSparseTerms (conversion.dtm, .4) conversion.sparse.matrix<-as.matrix(conversion.sparse.dtm, 
stringsAsFactors=F) #scale conversion.scaled<-conversion.sparse.matrix conversion.scaled[,1:ncol(conversion.sparse.matrix)]<- conversion.sparse.matrix[,1:ncol(conversion.sparse.matrix)]/scaling #this remakes the dtm in 
proper order nword=dim(conversion.scaled)[2] freq.dat<-array(0,c(20,nword)) freq.dat[1,]=conversion.scaled[1,] freq.dat[2,]=conversion.scaled[12,] for (j in 3:9){ 
freq.dat[j,]=conversion.scaled[11+j,] } for (j in 10:19){ freq.dat[j,]=conversion.scaled[j-8,] } freq.dat[20,]=conversion.scaled[13,] #Euclidean 
distance # conversion.dist<-dist(freq.dat, method = "Euclidean") # freq.dist<-as.matrix(conversion.dist) #Cosine distance 
cosine.dist<-simil(freq.dat, method = "cosine") freq.dist<-as.matrix(cosine.dist, stringsAsFactors=F) freq.dist<-pr_simil2dist(freq.dist) freq.dist[is.na(freq.dist)] <- 0 
#this sums the distances for each row and then averages 
them # for in-half1, inhalf2, crosshalf a=0 c=0 for (i 
in 1:10){ for (j in 1:i) a=a+freq.dist[i,j] for (j in 
11:20) c=c+freq.dist[i,j] } a=a/40 c=c/100 b=0 for (i in 11:20) 
for (j in 11:i) b=b+freq.dist[i,j] b=b/40 table[k,]=c(a,b,c) } #table[1,]=c(a,b,c) write.csv(table, 
file="binarytest_novel_German_cosine.csv") View(conversion.matrix) tdm<-t(conversion.tdm) tdm<-t(conversion.dtm) tdm<-as.matrix(tdm, stringsAsFactors=F) View(tdm) conversion.matrix<-as.matrix(conversion.dtm, stringsAsFactors=F) View(conversion.matrix) 
conversion.matrix<-as.matrix(conversion.dtm, stringsAsFactors=F) conversion.scaled<-conversion.matrix conversion.scaled[,1:ncol(conversion.matrix)]<- conversion.matrix[,1:ncol(conversion.matrix)]/scaling tdm<-t(conversion.scaled) View(tdm) mfw<-rowSums(tdm) mfw[1:10] mfw.sort<-sort(mfw) 
mfw.sort[1:10] mfw.sort<-sort(mfw, TRUE) mfw.sort[1:10] mfw.sort<-sort(mfw, TRUE)[1:500] mfw.sort<-as.data.frame(sort(mfw, TRUE)[1:500]) View(mfw.sort) mfw.dict<-row.names(mfw.sort) 
mfw.dict colnames(conversion.scaled) conversion.scaled.sub<-subset(conversion.scaled, colnames(conversion.scaled) %in% mfw.dict) mfw.dict conversion.scaled.sub<-conversion.scaled[,mfw.dict] conversion.scaled.sub View(conversion.scaled.sub) 
table<-array(0, c(153,3)) # second digit = # of works in 
corpus, third # = number of columns in table for 
(k in 3:152) { dir <- paste("/Users/andrewpiper/Sites/Topologies - Tests/Semantics of 
Life/Conversionality Test/Conversionality Test - Binary/Binary Test 1/binarytest1_new/DataNovelGerman20/", as.character(k), sep="") #load 
corpus conversion <- Corpus(DirSource(dir), readerControl=list(language="German")) conversion <- tm_map(conversion, function(x) iconv(enc2utf8(x), 
sub = "byte")) conversion <- tm_map(conversion, stripWhitespace) conversion <- tm_map(conversion, 
tolower) conversion <- tm_map(conversion, removePunctuation) conversion <- tm_map(conversion, removeNumbers) #remove 
problem words problems<-c("apparat","datumsangaben","seite","page","erlÃ¤uterungen", "kommentar") conversion <- tm_map(conversion, removeWords, problems) #dtm 
conversion.dtm<-DocumentTermMatrix(conversion, control=list(wordLengths=c(1,Inf))) #get scaling value conversion.matrix<-as.matrix(conversion.dtm, stringsAsFactors=F) scaling<-rowSums(conversion.matrix) #remove stopwords 
conversion <- tm_map(conversion, removeWords, stopwords("German")) #words<-c("ab", "ac", "ad ", "adhic 
", "aliqui ", "aliquis ", "an", "ante", "apud", "at", "atque", 
"aut", "autem", "cum", "cur", "de", "deinde", "dum", "ego", "enim", "ergo", 
"es", "est", "et", "etiam", "etsi", "ex", "fio", "haud", "hic", "iam", 
"idem", "igitur", "ille", "in", "infra", "inter", "interim", "ipse", "is", "ita", 
"magis", "modo", "mox", "nam", "ne", "nec", "necque", "neque", "nisi", "non", 
"nos", "o", "ob", "per", "possum", "post", "pro", "quae", "quam", "quare", 
"qui", "quia", "quicumque", "quidem", "quilibet", "quis", "quisnam", "quisquam", "quisque", "quisquis", 
